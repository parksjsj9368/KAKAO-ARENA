# 01장. 대회 살펴보기

<br>

<br>

## 1.1 대회 설명

<br>

- 주어진 추천 정보 : 콘텐츠 데이터, 작가와 사용자 데이터, 이용 행태 데이터

사용자가 본 글 정보, 본 글의 메타데이터, 본 글 본문 정보, 사용자 정보, 매거진 정보, 예측할 사용자 정보

<br>

- 브런치 글 추천

1) 유사글 추천 모델

1단계 : 지금 읽은 글과 유사한 글 찾는 타기팅 단계

  : CBF (콘텐츠)특징 추출, CF (사용자 행태)특징 추출, 통계기반 특징 추출

2단계 : 타기팅 된 글 중에서 사용자에게 반응이 좋은 글을 찾는 랭킹 단계

  : 실시간 랭킹 최적화의 탐색 과정 => *CTR 측정 => CTR 높은 글 선택

  : LinUCB, IMP-TS

2) 개인화 맞춤 추천 모델

1단계 : 추천할만한 글 찾는 타기팅 단계

  : 글의 CBF/CF 특징값과 메타정보(읽은수, 공유수, 댓글수)를 입력값으로 CTR 예측 모델을 통해 pCTR이 높은 상위글을 선택

  : 글의 정보로 예측 CTR 높은 글, *UX 편향 제거된 인기글, 통계 기반 분석

2단계 : 타기팅 된 글 중에서 사용자가 본 글 기반으로 내가 좋아할 만한 글 찾는 랭킹 단계

  : 전통적인 CF 방식인 사용자 피드백 데이터를 행렬 분해(ALS, Word2Vex)해 개인화 추천을 제공

  : 실시간 랭킹 모델

<br>

\* CTR : 클릭률, 특정 링크를 클릭한 사용자의 수

\* UX : 사용자 경험

<br>

<br>

## 1.2 대회 평가 척도

<br>

- 제출할 추천 결과

겹치는 기간(1주)와 미래(최대 2주) 기간 읽을 글 예측

<br>

- 평가 지표 

MAP와 NDCG (추천 정확도 : 랭킹 메트릭), Entropy Diversity (추천의 노출 다양성)

최종 순위는 보다 카운트로 계산 (각 세 등수 합, 골고루 높은 점수 유리)

<br>

<br>

## 1.3 데이터셋 설명

<br>

- 제공 데이터

1) 사용자가 본 글 정보

2) 본 글의 메타데이터

3) 본 글 본문 정보

4) 사용자 정보

5) 매거진 정보

6) 예측할 사용자 정보

<br>

<br>

## 1.4 데이터 탐색

<br>

- 브런치 글의 소비 데이터 현황

1) 브런치에서 소비가 가장 많은 두 글은 다른 일반 글 대비 소비수가 높아 특이값 가지기에 산점도에서 제외

2) 연도별 브런치 글 소비 수를 boxplot과 산점도 그려본 결과, 최신에 등록된 글의 소비 수가 높다

3) 글의 최신성이 중요하다

<br>

추가로)

1) 개별 글 보다는 매거진 글에서 소비 수가 높다

2) 소비 수가 높은 글 중에는 전문적인 주제에 대한 글 보다는 운동, 다이어트, 패션, 연애, 인간관계 와 같이 누구나 관심 있을 만한 주제 글이 많다

3) 18.07.30~18.08.12까지의 2주간 등록된 글의 소비가 높다

<br>

<br>

- 브런치 글의 등록일 이후 경과일에 따른 소비 현황

1) 글 소비수 기준으로 5%, 10%, 25% 이내 그룹으로 경과일에 따른 글 소비 수 꺾은선 그래프 확인

2) 대략적인 추이를 살펴보면, 등록일 이후 일정 시간이 지나면 감소하는 경향

3) 등록된 글의 경과일에 따른 평균 소비수 그래프 보면, 경과일 7일 이내로 소비하는 비중이 약 58%

4) 단, 유독 상위 5% 글에서 등록일 이후 일정 기간 경과한 후에 소비가 높아지는 글 보인다 => 다른 유통 채널에 브런치 글이 소개되면서 흥행으로 소비가 급증

<br>

- 위클리 매거진의 주기성

1) 등록된 글의 경과일에 따른 평균 소비수 그래프 보면, weekly 주기성을 갖는 패턴 발견

2) 발행일에 글 소비가 가장 높게 나타나고, 덩달아 이전 글들의 소비도 함께 증가한다

3) 초기 글 등록 후 1~2주 차에는 주기성을 확인하기 어렵지만, 3주 차부터는 weekly 주기성 뚜렷해진다

<br>

- 사용자 구독 데이터 현황

1) 98% 사용자가 구독 중인 작가가 있고, 평균 9명의 작가를 구독한다 

2) 전체 소비 중 구독 중인 작가의 글 소비가 1/3 정도 차지한다

<br>

<br>

<br>

# 02장. 글 추천 1등 솔루션

<br><br>

## 2.1 문제 이해

<br>

- 과거 기록의 기간과 예측할 소비의 기간

데이터가 제공되는 기간 : 2018.10.01~2019.03.01

예측하려는 기간 : 2019.02.22~2019.03.14

=> 제공과 예측이 "겹치는 1주일 기간"과 예측해야 하는 2주일 기간에 대해 별도의 모델을 구현해야 한다

<br>

<br>

사용자가 읽은 글을 예측하려면, 사용자들이 브런치 서비스를 어떻게 사용하는지를 직접 서비스를 이용하면서 확인해봐야 한다. 첫째로 방문한 이유와 유입 경로가 무엇인지, 둘째로 하나의 글을 읽은 후에 다음 읽을 글을 어떻게 선택할지 고민해봐야한다.

<br>

- 브런치 서비스 이해

1) 방문 이유 : 일반적인 블로그 서비스 방문 이유와 동일

2) 유입 경로 : 브런치, SNS(카카오톡), 검색(다음) 순서

3) 세션 특성 : 사용자가 글 읽은 후 바로 종료하지 않고 UX에 의한 추천이나 연결 링크 노출로 같은 작가의 글이나 동일 주제의 다른 글을 본다

4) 서비스 이용 패턴 : 글의 최신성이 중요, 전체 소비 중 구독 중인 작가 글의 소비가 1/3 정도 차지

<br>

<br>

## 2.2 데이터 이해

<br>

- 글 조회 데이터

사용자의 과거 글 소비 기록을 통해 독자들의 소비 성향을 판단하는 가장 중요한 데이터, 협업 필터링

1) 사용자별 글 조회 수를 분석한 결과, 평균 70회 중간값 10회 최대 8만건 이상으로 극단적으로 높은 사용자가 존재한다. 이러한 사용자는 이상치로 보고 제거하는 것이 효과적 일수도

2) 브런치 글마다 조회 수를 분석한 결과, 평균 42회 중간값 7회 최대 9만건 이상으로 극단적으로 높은 글이 존재한다. 

<br>

- 글의 메타데이터

작성된 글의 메타데이터 정보, 콘텐츠 기반 필터링

1) 작가별로 평균 33편의 글 작성

2) 매거진에는 평균 22.9편의 글 존재

3) 키워드 데이터는 글을 대표하는 중요 정보로, 전체 글 중 80%가 키워드를 가지고 평균 2.56개 최대 5개를 가지며 콘텐츠 기반 추천에 사용되기 적합

<br>

- 사용자(작가 혹은 독자) 정보

1) 전체 사용자의 97.7%는 작가 구독 중 => 추천 알고리즘에 사용되기 적합

2) 키워드 리스트 데이터는 작가 글로 유입되었던 검색 키워드로 60% 작가는 검색 키워드를 가진다

<br>

- 매거진 정보

1) 매거진 태그는 작가가 부여한 명확한 의도가 반영된 태그로 평균 2.8 최대 6개로 콘텐츠 기반필터링에 적합

<br>

<br>

## 2.3 예측 기간에 따른 추천 기술 적용

<br>

1) 20190222~20190228 : 조회 기록 데이터가 있기에(중첩 기간),,, 협업 필터링

2) 20190301~20190314 : 조회 기록 데이터가 없기에,,, 콘텐츠 기반 필터링

<br>

<br>

## 2.4 협업 필터링

<br>

많은 사용자의 많은 콘텐츠에 대한 선호도(= 명시적 피드백 데이터)를 확보하고 이를 통합적으로 활용해 추천 대상자가 선호할 만한 콘텐츠를 골라내는 기술

<br>

<br>

- 이웃 기반 협업 필터링 (= 메모리 기반 협업 필터링)

다수 사용자의 콘텐츠 이용 및 선호도 패턴을 이용해 사용자 취향 또는 콘텐츠의 속성을 수치화하고 사용간의 유사도 또는 콘텐츠 간의 유사도를 계산해 추천하는 기술

<br>

1) 사용자 기반 협업 필터링 : 나와 유사한 취향 가진 사람을 찾고 이들이 선호하는 콘텐츠 중 추천

2) 아이템 기반 협업 필터링 : 내가 좋아하는 콘텐츠와 가장 유사한 속성을 가진 콘텐츠 중 추천

<br>

<br>

- 세션 기반 협업 필터링 (= 시퀀스 기반 협업 필터링)

세션 단위의 조회 데이터에서 함께 이용되는 콘텐츠들을 유사성이 높은 콘텐츠로 정의해 유사도가 높은 콘텐츠를 추천

사용자를 구별하지 않고 모델 학습시키므로, 사용자와 아이템을 모두 구별해서 학습하는 이웃 기반 협업 필터링 보다 적은 데이터로 높은 성능을 얻을 수 있다

콘텐츠 조회의 순서를 활용해 학습하므로 콘텐츠의 최신성에 크게 영향을 받는 브런치 추천에 적합

<br>

1) *Word2Vec기반 추천

문장을 단어 단위로 나누고 개별 단어를 2개의 계층을 가지는 인공 신경망에 입력해 연속적으로 다음 단어를 예측하게 학습

문장에 포함되는 단어들을 수치 모음인 벡터 값으로 변환해 데이터 군집이나 단어 간의 관련성 측정

결과적으로 Article2Vec 모델을 구현해 조회 패턴이 유사한 글을 추천

<br>

\* Word2Vec

문장에 포함되는 단어들을 효율적으로 수치화하기 위해 고안된 기술

<br>

<br>

2) 연속 조회 통계 기반 추천

특정 글 읽은 직후나 특정 글 읽기 직전에 조회가 가장 많았던 글을 통계적으로 찾아 추천에 사용

<br>

<br>

\* article2vec 모델은 조회 패턴이 유사한 글을 추천하는 것이고 통계 기반 추천은 연속하여 많이 조회된 글을 추천하는 것 *

<br>

예) 예측 대상 사용자 1 : 글 B

사용자 2 : 글 A, 글 B, 글 C

사용자 3 : 글 A, 글 D, 글 C

=> article2ve 모델 : 글 D

=> 연속 조회 통계 : 글 A, 글 C

<br>

<br>

## 2.5 콘텐츠 필터링

<br>

콘텐츠가 가지고 있는 속성을 이용하여 추천 대상 사용자가 선호할 만한 콘텐츠를 골라내는 기술

협업 필터링에 반해 콘텐츠를 구별할 수 있는 속성이 존재해 신규 콘텐츠들도 추천 가능

<br>

첫번째로 독자가 구독하거나 독자가 과거에 읽은 글의 작가의 새글을 추천, 두번째로 작가가 작성하는 글의 종류와 독자가 조회하는 글의 종류가 비슷한 경우 해당 작가의 새글을 추천

<br>

<br>

- *Doc2Vec 기반 추천

독자의 취향과 작가의 취향을 키워드의 분포를 이용해 수치화하고 유사도를 계산

독자와 작가를 문서라고 생각하고 문서의 내용은 독자가 읽은 글과 작가가 작성한 글의 내용이라고 생각

결과적으로 User2Vec 모델을 구현해 독자와 작가를 벡터화해서 추천

<br>

*Doc2Vec : 문서를 벡터로 수치화하고 벡터 공간에 점으로 표현하는 기술

<br>

<br>

- 조회 기록이 없는 데이터 경우

인기글 추천(조회수가 많은 최대의 3개의 글 아이디) or 무작위 추천

<br>

<br>

## 2.6 앙상블

<br>

- 앙상블 : 여러 모델의 예측 결과를 결합하여 사용하는 것 = "하이브리드 필터링"

<br>

- 콘텐츠 + 협업 앙상블 했을 때 중복 제거하고 글 개수가 100개 미만일 경우

신규성이 있는 추천 글은 과거에 소비했던 작가들의 신규 글을 우선적으로 추천

<br>