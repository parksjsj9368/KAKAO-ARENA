# 01장. 대회 살펴보기

<br>

<br>

## 1.1 대회 설명

<br>

- 주어진 상품 정보

상품명, 브랜드, 정제된 상품명, 생산자명, 가격, 대표 이미지 피처

<br>

- 상품 자동 분류 솔루션

대분류 => 중분류 => 소분류 => 세분류 4단계로 분류

<br>

- 데이터 자동 분류기

기존 카테고리 매핑 상품들의 카테고리와 상품명에 들어 있는 모든 단어를 학습하여 자동 매핑시켜주는 방법

<br>

<br>

## 1.2 대회 평가 척도

<br>

- 카테고리 단계별 정확도

(카테고리 분류 정답 상품 수) / (카테고리 단계의 전체 상품 수)

<br>

- 전체 정확도

( (대분류 정확도)*1.0 + (중분류 정확도)*1.2 + (소분류 정확도)*1.3 + (세분류 정확도)*1.4 ) / 4

<br>

<br>

## 1.3 데이터셋 설명

<br>

- 제공 데이터

1) 카테고리 매핑 정보 : 대분류 / 중분류 / 소분류 / 세분류 : {카테고리 이름 : 카테고리 식별값,,,}

2) train 데이터셋 : 상품 식별자, 상품명, 브랜드명, 정제된 상품명, 제조사, 가격, 상품이 업데이트된 시간, 대분류 / 중분류 / 소분류 / 세분류 카테고리 식별값, 상품 대표 이미지

​    : 813만개

3) dev 데이터셋 : 50만개

4) test 데이터셋 : 150만개

<br>

<br>

## 1.4 데이터 탐색

<br>

- 상품 카테고리 분류 분포

1) 상품 카테고리별 상품 수가 얼마나 편중되어 있는지

2) 상품 카테고리별 상품 수 그래프와 *비대칭도(skewness) 확인

3) 소분류 > 세분류 > 중분류 > 대분류 순서로 상품 카테고리가 편중되어 있다

<br>

\* 왜도 = 분포의 비대칭도를 나타내는 통계량

왜도 = 0 : 대칭인 분포

왜도 > 0 : 오른쪽으로 긴 꼬리

왜도 < 0 : 왼쪽으로 긴 꼬리

비대칭도가 커질수록, 왜도의 절댓값은 증가한다

<br>

<br>

- 상품명에 담긴 정보

1) 상품명에는 상품의 유일한 식별값, 카테고리 정보, 성별, 속성 등의 정보가 들어있다

2) 텍스트 정보를 잘 분석하면 카테고리 분류에 많은 도움이 된다

3) 정제되지 않은 문장(띄워쓰기, '_'문자)을 적절한 단어나 의미로 구분하는 텍스트 전처리가 필요하다

4) 서브워드 단위로 분리하는 *BPE(Byte Pair Encoding) 알고리즘이 활용되었다

<br>

\* OOV(Out-Of-Vocabulary) 문제

기계가 모르는 단어가 등장하면 그 단어를 단어 집합에 없는 단어란 의미에서 OOV라고 표현

\* BPE(Byte Pair Encoding) = OOV 문제를 완화하는 대표적인 서브워드 분리 알고리즘

서브워드 분리 작업 : 하나의 단어를 더 작은 단위의 여러 서브워드로 분리해서 단어를 인코딩 및 임베딩하는 전처리 과정

서브워드 분리 알고리즘을 통해 OOV나 희귀단어, 신조어와 같은 문제를 완화시킨다

참고) https://wikidocs.net/22592

<br>

<br>

- 사용 빈도가 높은 단어

1) 상품명, 브랜드명, 제조사, 정제된 상품명의 사용 빈도가 높은 단어로 wordcloud 시각화

2) 상품명과 정제된 상품명의 텍스트에 카테고리 이름 정보와 비슷한 단어들이 많이 출현된다

<br>

- 이미지 피처 시각화

1) 상품 이미지 피처가 카테고리별로 유사한지 확인

2) *t-SNE로 데이터를 2차원 평면으로 차원 축소 후 대분류 카테고리 기준으로 시각화

3) 상품들이 적절히 군집화 된 것을 보면, 상품 이미지 피처는 카테고리 특징을 담고 있다

<br>

\* 차원의 저주

데이터 학습을 위해 차원이 증가하면서, 학습 데이터 수가 차원의 수보다 적어져 성능이 저하되는 현상

즉, 차원이 증가함에 따라(= 변수의 수 증가) 모델의 성능이 안좋아지는 현상

\* 차원 축소

사용 이유 : 1) 차원의 저주를 해결하기 위해

   2) 3개 이상(3차원)의 피처가 존재 할 경우 시각화가 어려워서 데이터 특성 파악이 어렵다

방식 : 1) 피처 선택(= Feature Selection) : 주요 필드 몇 개만 선택

  2) 피처 추출(= Feature Extraction) : 원본과 전혀 다른 형태의 데이터를 추출 ex) PCA, t-SNE

<br>

\* PCA

데이터 변화의 폭을 가장 큰 축으로 정하고 그와 직교하는 축을 구한다

각 피처 별, 값의 변화도(= Variance, 해당 축의 값이 얼마나 크게 변하는가)를 보고 피처 선택

선형 분석 방식으로 값을 사상하기 때문에, 군집화 되어 있는 데이터 중 중첩 되는 부분은 제대로 구별 할 수 없는 문제점 발생

\* t-SNE = t-분포 확률적 임베딩

중첩 현상을 줄여주는 차원 감소 기법으로 군집이 중복되지 않는 장점으로 시각화를 통한 데이터 분석에는 유용

매번 계산 할 때 마다 축의 위치가 바뀌어서 다른 모양으로 나타나기에 머신러닝 모델의 학습 피처로 사용하기에는 어렵다

<br>

<br>

<br>

# 02장. 쇼핑몰 상품 카테고리 분류 1등 솔루션

<br>

<br>

## 2.1 머신러닝 파이프라인 구현 

<br>

**데이터 전처리 => 학습 => 추론 => 리더보드 제출**

- 데이터 전처리 : 대회 데이터 로드, 데이터프레임으로 변환, 피처 엔지니어링, 전처리된 데이터 저장
- 학습 : 모델 아키텍처 선정 및 구현, 학습셋으로 모델 학습, 검증 전략 적용, 학습된 모델을 파일로 저장
- 추론 : 데브셋 상품 카테고리 예측, 예측을 제출 파일로 저장

<br>

<br>

## 2.2 피처 엔지니어링

<br>

원시 데이터에서 모델의 성능 향상을 위한 목적으로 데이터를 가공하는 과정

: 새로운 컬럼을 추가하거나 불필요한/중복된/노이즈 많은 컬럼 제거

<br>

- 카테고리 이름 칼럼 추가

데이터 분석에 도움이 되도록 숫자로 기록된 카테고리 칼럼의 값을 카테고리 매핑 정보 데이터를 이용해 한글 이름으로 바꿔준다

<br>

- 칼럼별 중요성 따져보기

불필요한 칼럼을 제거할 때 근거로 사용

1) pid 칼럼 : 개별 상품의 고유 ID, 임의로 부여된 코드로 타깃을 예측하는데 불필요한 정보

2) product 칼럼 : 상품명으로서 상품이 무엇인지를 설명, 타깃을 예측하는데 직접적으로 필요한 정보

3) brand 칼럼 : 상품의 브랜드명, 브랜드는 특정 상품군이나 회사를 대표하는 단어로 브랜드를 통해 상품이 어떤 카테고리에 속할지 유추, 타깃을 예측하는데 필요한 정보

 : 상위 10개의 브랜드별 빈도수를 보았을 때, 절반 이상의 데이터가 예측에 도움이 되지 않는다

4) maker 칼럼 : 상품의 제조사

 : 상위 10개의 제조사별 빈도수를 보았을 때, 절반 이상의 데이터가 예측에 도움이 되지 않는다

5) model 칼럼 : 상품명을 정제 알고리즘으로 정제한 결과

6) price 칼럼 : 상품의 가격 정보, 상품의 종류, 가치, 브랜드 등에 따라 가격이 매겨지기에 가격 정보는 타깃을 예측하는데 필요한 정보

 : 가격별 빈도를 보았을 때, -1값(가격 정보 없음)이 절반 이상 존재

<br>

- 정답을 예측하는데 도움이 될 칼럼 선택하기 / 불필요한 칼럼을 제외한 새로운 데이터프레임 만들기

이미 다른 컬럼에서 충분히 정보를 보유하고 있는 중복된 피처나 노이즈가 많이 섞인 피처를 사용하면 모델의 예측 성능이 떨어질 수 있다

1) brand, maker, model 칼럼은 절반 정도의 데이터에는 타깃 예측을 위해 필요한 정보가 담겨있지 않다. 게다가 product인 상품명에 이미 포함된 정보가 많다.

2) brand, maker, model 칼럼 제외

3) price 칼럼 또한 가격 정보가 없는 비중이 크다, 그렇지만 product에는 없는 정보이기에 타깃 예측에 도움이 될 수도 있다

4) price 칼럼을 포함했을 때의 예측 결과와 미포함했을 때의 예측 결과를 비교해서 최종 포함 여부를 결정한다

\* 결측치가 많다고 무조건적 삭제는 옳지 않다 ! 다만 다른 변수에서 특정 변수를 내포하는게 있는지 확인해보고, 없다면 특정 칼럼을 포함했을 때와 미포함했을 때의 결과를 비교해 최종 포함 여부를 결정한다 *

<br>

- 기존 칼럼을 가공해 새로운 칼럼 추가하기

1) 띄어쓰기, 특수기호, 연속된 특수기호 => 하나의 공백문자로 치환

2) 영어는 모두 소문자로 변경

3) 문장의 단어 분절 => 구글에서 오픈소스 '센텐스피스' 라이브러리

일반 문장과 다른 상품명의 특성 때문에 konlpy 한국어 형태소 분석기를 사용하지 않고 센텐스피스 분절기 사용

4) 분절한 결과로 새로운 tokens 칼럼 생성

<br>

=> 최종적으로 선택된 칼럼 : 상품명(tokens)와 이미지(img_feat)

<br><br>

## 2.3 모델 아키텍처 선정 및 구현

<br>

모델의 입력은 상품 정보이고, 출력은 분류 정보이다

<br>

- 모델 아키텍처 선정

솔루션 모델 : 텍스트 인코더, 이미지 인코더, 카테고리 분류기 모듈

<br>

- 텍스트 인코더 = tokens 칼럼의 상품명을 인코딩해 텍스트 벡터로 만드는 모듈

인코딩 과정은 상품명의 각 토근을 임베딩(토근에 대응되는 벡터를 룩업 테이블에서 찾아서 치환)하고 이들을 취합 정보를 가지고 벡터를 만드는 것

토큰처럼 연속된 시퀀스 데이터를 다루기 위해 트랜스포머 사용

구글에서 제안한 언어 모델 버트 : 토큰 임베딩 + 세그먼트 임베딩 + 포지션 임베딩 => 최종 임베딩

<br>

\* 연속된 시퀀스 데이터를 다루는 주요 모듈

1) 트랜스포머 기반의 인코더 : TRM 셀 1번만 거친다, 잔차 연결 가능 

2) lstm기반의 텍스트 인코더 : 시퀀스 데이터 길이만큼 셀 거친다

셀을 많이 거칠수록 정보가 변형될 가능성이 높아진다

\* 시퀀스 데이터 : 데이터 내 각 요소가 순서를 가지고 배열된 데이터, 순서가 바뀌면 데이터가 내포한 정보가 변경되거나 손실

<br>

<br>

- 이미지 인코더 = imf_feat 칼럼의 상품 이미지를 인코딩해 이미지 벡터로 변환하는 모듈

ResNet(Residual Network) : CNN 계열에서 잔차 연결로 깊은 신경망을 학습할 수 있게 만든 아키텍처

​     : 레지듀얼 블록과 아이덴티티 블록의 반복으로 신경망 깊이를 조정할 수 있다

<br>

- 카테고리 분류기

앞서 두 모듈이 만들어 낸 [텍스트벡터; 이미지벡터]를 결합한 벡터를 입력 받아 대/중/소/세 카테고리를 예측하는 모듈

대/중/소/세 각 카테고리별 분류기 = 총 4개의 분류기

<br>

\* 카테고리별 개별 분류기를 만든 이유 : 데이터의 불균형 문제(특정 결합에 쏠림 데이터)를 완화하기 위해

<br>

<br>

## 2.4 모델 학습

<br>

- 최적의 파라미터로 업데이트

1) 반복적인 파라미터 업데이트

2) 업데이트 속도는 초기 학습률과 스케줄러로 조절 및 제어

3) 파라미터 업데이트 속도에 관성을 주거나 파라미터별로 다른 학습률을 적용하기 위한 옵티마이저 선택

<br>

\* 옵티마이저 : 모델의 파라미터를 빠르고 안정적으로 업데이트 하기 위한 역할, 손실이 최소화되는 방향으로 모델의 어떤 파라미터를 얼마나 업데이트할 것인지 결정

\* 스케줄러 : 학습 과정 중에 학습률을 조절하는 역할, 선형 스케줄과 웜업

<br>

<br>

- 계층적 k-폴드 교차검증

*k-폴드는 검증셋에는 속하지만 학습셋에는 속하지 않은 클래스가 존재한다는 문제가 발생

-stratified 옵션을 통해 데이터 그룹을 구성해서 학습 할 수 있다

<br>

\* k-폴드 교차검증 : 하나의 데이터 그룹이 아닌 k개의 데이터 그룹으로 모델을 검증하는 방법

<br>

- k-폴드 평균 앙상블

앙상블 : 여러 모델의 예측 결과를 섞어서 예측 성능을 향상

k-폴드 평균 앙상블 : k개의 데이터 그룹에서 학습된 k개의 모델의 출력을 단순 평균 하는 것

<br>